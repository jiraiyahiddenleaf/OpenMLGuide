# Tuned Models

Within the realm of LLMs, the "Tune model" assumes a position of paramount significance. Exacting fine-tuning on dedicated datasets empowers it to excel in various tasks, encompassing image classification, sentiment analysis, and language translation. This refined model serves as the foundational underpinning for innovative AI applications, notably within the domains of healthcare, autonomous vehicle technology, and augmented reality.

![training model img](/static/img/tuneModel.png)

### Models

| Models                                                                  | Developed by                                          | Release Date | Parameter                                                                                                                  | Description                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| ----------------------------------------------------------------------- | ----------------------------------------------------- | ------------ | -------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| [Mistral](https://mistral.ai/product/)                                  | Ashvini Kumar Jindal                                  |              | [Arithmo-Mistral-7B](https://huggingface.co/akjindal53244/Arithmo-Mistral-7B)                                              | Trained to reason and answer mathematical problems and is also capable of writing a Python program that upon execution prints answer to the question, used Mistral-7B as a base model and used QLoRA to fine-tune it on a single RTX 4090 GPU.                                                                                                                                                                                                         |
| [Falcon](https://falconllm.tii.ae/)                                     | Teknium                                               |              | [OpenHermes-2-Mistral-7B](https://huggingface.co/teknium/OpenHermes-2-Mistral-7B)                                          | Trained on 900k entries of GPT-4 generated data from diverse open AI datasets, it underwent extensive filtering and format conversion to ShareGPT, followed by ChatML transformation.                                                                                                                                                                                                                                                                  |
| [LLaVA](https://llava-vl.github.io/)                                    | Haotian Liu                                           |              | [LLaVA-7B](https://huggingface.co/liuhaotian/llava-v1.5-7b), [LLaVA-13B](https://huggingface.co/liuhaotian/llava-v1.5-13b) | LLaVA-1.5 excels in 11 benchmarks with minimal changes from LLaVA, using only public data, quick training in ~1 day on a single 8-A100 node, and outperforming billion-scale data methods. It's a powerful multimodal model, rivaling GPT-4 in chat capabilities and setting a new Science QA accuracy record.                                                                                                                                         |
| [zephyr-7b-alpha](https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha) | [HuggingFaceH4](https://huggingface.co/HuggingFaceH4) |              | [zephyr-7b-alpha](https://huggingface.co/HuggingFaceH4/zephyr-7b-alpha)                                                    | Zephyr-7B-Alpha, from Hugging Face's Zephyr series, is a GPT-like language model with 7B parameters. While it aims to be a helpful assistant, it's not fine-tuned for human preferences and may produce problematic outputs. It's based on Mistral-7B-v0.1, mainly trained on English data and available under the CC BY-NC 4.0 license.                                                                                                               |
| [SSD-1B](https://mistral.ai/product/)                                   | [Segmind](https://huggingface.co/segmind)             |              | [SSD-1B](https://huggingface.co/segmind/SSD-1B)                                                                            | Segmind's SSD-1B is a compact, faster variant of SDXL, maintaining top-notch text-to-image generation. Trained on diverse datasets, it uses knowledge distillation from expert models like [SDXL](https://huggingface.co/stabilityai/sdxl-vae), [ZavyChromaXL](https://huggingface.co/stablediffusionapi/zavychromaxl), and [JuggernautXL](https://huggingface.co/stablediffusionapi/juggernaut-xl-v5) to create impressive visuals from text prompts. |
| [MistralLite](https://huggingface.co/amazon/MistralLite)                | [Amazon](https://huggingface.co/amazon)               |              | [MistralLite](https://huggingface.co/amazon/MistralLite)                                                                   | MistralLite, a fine-tuned AWS model on Hugging Face, handles long context efficiently (up to 32K tokens) with adapted Rotary Embedding. It's ideal for tasks like topic retrieval, summarization, and Q&A. Deployable on AWS g5.2x instances with Sagemaker Huggingface Text Generation Inference. Supports Python usage and is Apache 2.0 licensed.                                                                                                   |
| [MetaMath](https://huggingface.co/meta-math/MetaMath-7B-V1.0)           | [Meta-Math](https://meta-math.github.io/)             |              | [MetaMath-7B](https://huggingface.co/meta-math/MetaMath-7B-V1.0)                                                           | MetaMath is a project for enhancing mathematical questions for language models. It builds the MetaMathQA dataset and fine-tunes LLaMA-2 models, creating specialized mathematical reasoning models. Results show MetaMath's significant performance lead on GSM8K and MATH benchmarks, even surpassing models of the same size.                                                                                                                        |
